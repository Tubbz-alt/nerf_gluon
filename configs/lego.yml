# Parameters to setup experiment.
experiment:
  # Unique experiment identifier
  id: lego-lowres3_Adam_fine
  # Seed for random number generators (for repeatability).
  randomseed: 42  # Cause, why not?
  # Experiment logs will be stored at "logdir"/"id"
  logdir: logs
  # Number of training iterations.
  num_epochs: 1500
  # Number of training iterations after which to calculate training accuracy.
  print_training_acc_every: 10
  # Number of training iterations after which to validate.
  validate_every: 20
  # Number of training iterations after which to save images.
  save_image_every: 20
  # Number of training iterations after which to checkpoint.
  save_checkpoint_every: 60


# Dataset parameters.
dataset:
  # Type of dataset (Blender vs LLFF vs DeepVoxels vs something else)
  type: blender
  # Provide a path to the pre-cached dataset dir
  cachedir: F:\Datasets\Nerf\nerf_example_data\nerf_synthetic\lego\cache
  # For the Blender datasets (synthetic), optionally return images
  # at half the original resolution of 800 x 800, to save space.
  half_res: False
  # Stride (include one per "testskip" images in the dataset).
  testskip: 1
  # Do not use NDC (normalized device coordinates). Usually True for
  # synthetic (Blender) datasets.
  no_ndc: True
  # Near clip plane (clip all depth values closer than this threshold).
  near: 2
  # Far clip plane (clip all depth values farther than this threshold).
  far: 6


# Model parameters.
models:
  # Positional Encoding
  encoding:
    # Whether to include the position (xyz) itself in its positional
    # encoding.
    include_input_xyz: True
    # Number of encoding functions to use in the positional encoding
    # of the coordinates.
    num_encoding_fn_xyz: 10
    # Whether or not to perform log sampling in the positional encoding
    # of the coordinates.
    log_sampling_xyz: True
    # Whether to include the direction itself in its positional encoding.
    include_input_dir: True
    # Number of encoding functions to use in the positional encoding
    # of the direction.
    num_encoding_fn_dir: 4
    # Whether or not to perform log sampling in the positional encoding
    # of the direction.
    log_sampling_dir: True

  # Coarse model.
  coarse:
    # Name of the torch.nn.Module class that implements the model.
    type: PaperNeRFModel
    # Number of layers in the model.
    num_layers: 8
    # Number of hidden units in each layer of the MLP (multi-layer
    # perceptron).
    hidden_size: 256
    # Add a skip connection once in a while. Note: This parameter
    # won't take affect unless num_layers > skip_connect_every.
    skip_connect_every: 4

  # Fine model.
  fine:
    # Set whether to use same model (and parameters) for both coarse and fine or not
    shared_network: True
    # Name of the torch.nn.Module class that implements the model.
    type: PaperNeRFModel
    # Number of layers in the model.
    num_layers: 8
    # Number of hidden units in each layer of the MLP (multi-layer
    # perceptron).
    hidden_size: 256
    # Add a skip connection once in a while. Note: This parameter
    # won't take affect unless num_layers > skip_connect_every.
    skip_connect_every: 4


# Optimizer params.
optimizer:
  # Name of the torch.optim class used for optimization.
  type: adam
  # Learning rate.
  lr: 5.0e-4 # 5.0E-3 = 0.005
  # Weight decay
  wd: 0.0


# Learning rate schedule.
scheduler:
  # Update learning rate at epochs inside the array
  update_lr_in_epochs: [250, 700]
  # Rate at which to apply this decay.
  lr_decay_factor: 0.1


# NeRF parameters.
nerf:
  # Use viewing directions as input, in addition to the X, Y, Z coordinates.
  use_viewdirs: True
  # Training-specific parameters.
  train:
    # Number of random rays to retain from each image.
    # These sampled rays are used for training, and the others are discarded.
    num_random_rays: 1024  # 32 * 32 * 4
    # Size of each chunk (rays are batched into "chunks" and passed through
    # the network)
    chunksize: 16384  # 131072  # 1024 * 32
    # Whether or not to perturb the sampled depth values.
    perturb: True
    # Number of depth samples per ray for the coarse network.
    num_coarse: 64
    # Number of depth samples per ray for the fine network.
    num_fine: 64
    # Whether to render models using a white background.
    white_background: False
    # Standard deviation of noise to be added to the radiance field when
    # performing volume rendering.
    radiance_field_noise_std: 0.2
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
  # Validation-specific parameters.
  validation:
    # Number of random rays to retain from each image.
    # These sampled rays are used for training, and the others are discarded.
    chunksize: 4096   # 1024 * 32
    # Whether or not to perturb the sampled depth values.
    perturb: False
    # Number of depth samples per ray for the coarse network.
    num_coarse: 64
    # Number of depth samples per ray for the fine network.
    num_fine: 64
    # Whether to render models using a white background.
    white_background: False
    # Standard deviation of noise to be added to the radiance field when
    # performing volume rendering.
    radiance_field_noise_std: 0.
    # Sample linearly in disparity space, as opposed to in depth space.
    lindisp: False
